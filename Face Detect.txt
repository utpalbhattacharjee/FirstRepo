#   ---------Collecting the dataset---------





import cv2
import numpy as np
face_classifier= cv2.CascadeClassifier('C:/Users/user/Anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')

def face_extractor(img):
    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    faces= face_classifier.detectMultiScale(gray,1.3,5)
    
    if faces is():
        return None
    for(x,y,w,h) in faces:
        cropped_face= img[y:y+h, x:x+w]
        
    return cropped_face 
    
    

cap= cv2.VideoCapture(0)
count= 0

while True:
    ret, frame=cap.read()
    if face_extractor(frame) is not None:
        count+=1
        face= cv2.resize(face_extractor(frame),(200,200))
        face= cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        
        
        file_name_path= 'C:/Users/user/Pictures/faces/user' +str(count)+'.jpg'
        
        cv2.imwrite(file_name_path,face)
        
        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)
        cv2.imshow('Face Cropper',face)
    else:
        print("Face not Found")
        pass
    if cv2.waitKey(1)==13 or count==180:
        cap.release()
        cv2.destroyAllWindows()
        break
    

print('collecting samples complete!!!')






#   ---------Training the model---------

import cv2
import numpy as np
from os import listdir
from os.path import isfile, join
from playsound import playsound
data_path= 'C:/Users/user/Pictures/faces/'
onlyfiles= [f for f in listdir(data_path) if isfile(join(data_path,f))]


Training_Data, Labels= [], []

for i,files in enumerate(onlyfiles):
    image_path=data_path + onlyfiles[i]
    images= cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    Training_Data.append(np.asarray(images, dtype=np.uint8))
    Labels.append(i)
    
labels= np.asanyarray(Labels, dtype=np.int32)

model= cv2.face.LBPHFaceRecognizer_create()

model.train(np.asanyarray(Training_Data), np.asanyarray(Labels))

print("Model Training Complete!!!")




#   ---------Testing the model---------

face_classifier= cv2.CascadeClassifier('C:/Users/user/Anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')

def face_detector(img, size=0.5):
    gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces= face_classifier.detectMultiScale(gray,1.3,5)
    
    if faces is():
        return img,[]
        print("Face found!!!")
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)
        roi= img[y:y+h, x:x+w]
        roi= cv2.resize(roi,(200,200))
        
    return img,roi

cap=cv2.VideoCapture(0)
playsound('output.wav')
while True:
    ret,frame= cap.read()   
    image, face= face_detector(frame)
    
    cv2.imshow('Face Cropper', image)
    
    try:
        face= cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
        result= model.predict(face)
        if result[1] <500:
            confidence= int(100*(1-(result[1])/300))
            display_string= "Hi Utpal " + str(confidence) + "% Confidence it is you."
            cv2.putText(image,display_string,(30,30),cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)
        
        if confidence>75:
            display_string1= str(confidence) + "% Confidence it is user"
            cv2.putText(image,display_string1,(100,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)
            cv2.imshow('Face Cropper', image)
        
        else:
            cv2.putText(image,"Locked",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)
            cv2.imshow('Face Cropper', image)
        
    except:
        cv2.putText(image,"Face not found",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)
        cv2.imshow('Face Cropper', image)
        pass
            
    if cv2.waitKey(1)==13:
        cap.release()
        cv2.destroyAllWindows()
        break